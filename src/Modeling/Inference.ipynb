{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "db5208429cfa4917"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.539177Z",
     "start_time": "2024-11-25T12:26:06.727479Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Huggingface\n",
    "import huggingface_hub\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Unsloth\n",
    "from unsloth import FastLanguageModel, is_bf16_supported"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "57abf30d627ee09e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.544513Z",
     "start_time": "2024-11-25T12:26:11.540573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    # Model\n",
    "    model_id: str = \"PathFinderKR/KHU-Llama-3.2-1B-Instruct-SFT\"\n",
    "    model_type: str = \"instruct\"\n",
    "    \n",
    "    # Inference\n",
    "    max_new_tokens: int = 2048\n",
    "    do_sample: bool = True\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    repetition_penalty: float = 1.1\n",
    "    dtype: torch.dtype = torch.bfloat16 if is_bf16_supported() else torch.float16\n",
    "    load_in_4bit: bool = True\n",
    "    \n",
    "    # Device\n",
    "    device: torch.device = None\n",
    "    \n",
    "    # Seed\n",
    "    seed: int = 42"
   ],
   "id": "1e40d5f72df04655",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "f46db0f1bc936647"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.556034Z",
     "start_time": "2024-11-25T12:26:11.545793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "set_seed(CONFIG.seed)"
   ],
   "id": "8af068b3748857a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "fbfd69b58b4f084"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.563668Z",
     "start_time": "2024-11-25T12:26:11.557314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"> Running on MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "28da07e74fabc081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## HuggingFace",
   "id": "696491e2e0ee1f7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.850318Z",
     "start_time": "2024-11-25T12:26:11.565107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "huggingface_hub.login(\n",
    "    token=os.getenv(\"HUGGINGFACE_TOKEN\"),\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "id": "aa612bd605c0a3d6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "af7858b04f878907"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:30:02.747936Z",
     "start_time": "2024-11-25T12:26:11.851462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=CONFIG.model_id,\n",
    "    max_seq_length=CONFIG.max_new_tokens,\n",
    "    dtype=CONFIG.dtype,\n",
    "    load_in_4bit=CONFIG.load_in_4bit\n",
    ")"
   ],
   "id": "5db78c3baf173b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.8: Fast Llama patching. Transformers = 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4080 SUPER. Max memory: 15.992 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1. CUDA = 8.9. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8368b0b92f4e48e8959c2a63dc7edc52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99715264123d435f9946fcb19334b177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "923f5b54d7164d0894e8227fbf5032e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da18805aeb004add9dfecb190125caeb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90ff4fd31b8543de8ffd8062c6ed3ab1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:30:02.751653Z",
     "start_time": "2024-11-25T12:30:02.749224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "text_streamer = TextStreamer(tokenizer)"
   ],
   "id": "d0685ccc663499a9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "855210326205f00c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:30:02.761302Z",
     "start_time": "2024-11-25T12:30:02.752738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_3_instruct_prompt = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{}\"\"\"\n",
    "\n",
    "# Generate base model\n",
    "def generate_text(prompt):\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    inputs = tokenizer(\n",
    "    [\n",
    "        prompt\n",
    "    ], return_tensors = \"pt\").to(CONFIG.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=CONFIG.max_new_tokens,\n",
    "        do_sample=CONFIG.do_sample,\n",
    "        temperature=CONFIG.temperature,\n",
    "        top_p=CONFIG.top_p,\n",
    "        repetition_penalty=CONFIG.repetition_penalty,\n",
    "        use_cache=True,\n",
    "        streamer=TextStreamer(tokenizer)\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
    "\n",
    "# Generate instruction model\n",
    "def generate_response(system, user):\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    inputs = tokenizer(\n",
    "    [\n",
    "        llama_3_instruct_prompt.format(\n",
    "            system,\n",
    "            user,\n",
    "            \"\"\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(CONFIG.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=CONFIG.max_new_tokens,\n",
    "        do_sample=CONFIG.do_sample,\n",
    "        temperature=CONFIG.temperature,\n",
    "        top_p=CONFIG.top_p,\n",
    "        repetition_penalty=CONFIG.repetition_penalty,\n",
    "        use_cache=True,\n",
    "        streamer=TextStreamer(tokenizer)\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=False)"
   ],
   "id": "acd28280dfdca5d6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:48:24.327712Z",
     "start_time": "2024-11-25T12:48:21.107922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if CONFIG.model_type == \"base\":\n",
    "    sample_text = \"Capital of France:\"\n",
    "    sample_response = generate_text(sample_text)\n",
    "    print(sample_response)\n",
    "    print(tokenizer.tokenize(sample_response[0]))\n",
    "elif CONFIG.model_type == \"instruct\":\n",
    "    sample_system = \"You're name is KHUrious. You are an expert in Kyung Hee University's academic system.\"\n",
    "    sample_user = \"Are the graduation credit requirements for Mechanical Engineering higher compared to other departments?\"\n",
    "    sample_response = generate_response(sample_system, sample_user)\n",
    "    print(sample_response)\n",
    "    print(tokenizer.tokenize(sample_response[0]))"
   ],
   "id": "bcb8683e4df9bdfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You're name is KHUrious. You are an expert in Kyung Hee University's academic system.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Are the graduation credit requirements for Mechanical Engineering higher compared to other departments?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Yes, the graduation credit requirement for the Mechanical Engineering department is indeed higher than what is typically expected across all engineering disciplines and many non-engineering majors. Specifically, it involves completing a total of 54 credits, which includes:\\n\\n1. **Major Basics**: 6 credits\\n2. **Major Required Courses**: 15 credits\\n3. **Electives (Specialization)**: 9 credits\\n4. **Total Major Credits**: 60 credits\\nThis stringent requirement reflects the program's commitment to providing a comprehensive education that prepares students for advanced research and industry applications within the field of mechanical engineering. The emphasis on both required and elective courses ensures that graduates not only possess core knowledge but also have the flexibility to tailor their education according to their interests and career goals.<|eot_id|>\n",
      "[\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou're name is KHUrious. You are an expert in Kyung Hee University's academic system.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAre the graduation credit requirements for Mechanical Engineering higher compared to other departments?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYes, the graduation credit requirement for the Mechanical Engineering department is indeed higher than what is typically expected across all engineering disciplines and many non-engineering majors. Specifically, it involves completing a total of 54 credits, which includes:\\\\n\\\\n1. **Major Basics**: 6 credits\\\\n2. **Major Required Courses**: 15 credits\\\\n3. **Electives (Specialization)**: 9 credits\\\\n4. **Total Major Credits**: 60 credits\\\\nThis stringent requirement reflects the program's commitment to providing a comprehensive education that prepares students for advanced research and industry applications within the field of mechanical engineering. The emphasis on both required and elective courses ensures that graduates not only possess core knowledge but also have the flexibility to tailor their education according to their interests and career goals.<|eot_id|>\"]\n",
      "['<|begin_of_text|>', '<|start_header_id|>', 'system', '<|end_header_id|>', 'ÄŠÄŠ', 'You', \"'re\", 'Ä name', 'Ä is', 'Ä KH', 'Uri', 'ous', '.', 'Ä You', 'Ä are', 'Ä an', 'Ä expert', 'Ä in', 'Ä Ky', 'ung', 'Ä He', 'e', 'Ä University', \"'s\", 'Ä academic', 'Ä system', '.', '<|eot_id|>', '<|start_header_id|>', 'user', '<|end_header_id|>', 'ÄŠÄŠ', 'Are', 'Ä the', 'Ä graduation', 'Ä credit', 'Ä requirements', 'Ä for', 'Ä Mechanical', 'Ä Engineering', 'Ä higher', 'Ä compared', 'Ä to', 'Ä other', 'Ä departments', '?', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'ÄŠÄŠ', 'Yes', ',', 'Ä the', 'Ä graduation', 'Ä credit', 'Ä requirement', 'Ä for', 'Ä the', 'Ä Mechanical', 'Ä Engineering', 'Ä department', 'Ä is', 'Ä indeed', 'Ä higher', 'Ä than', 'Ä what', 'Ä is', 'Ä typically', 'Ä expected', 'Ä across', 'Ä all', 'Ä engineering', 'Ä disciplines', 'Ä and', 'Ä many', 'Ä non', '-engine', 'ering', 'Ä majors', '.', 'Ä Specifically', ',', 'Ä it', 'Ä involves', 'Ä completing', 'Ä a', 'Ä total', 'Ä of', 'Ä ', '54', 'Ä credits', ',', 'Ä which', 'Ä includes', ':\\\\', 'n', '\\\\n', '1', '.', 'Ä **', 'Major', 'Ä Basics', '**:', 'Ä ', '6', 'Ä credits', '\\\\n', '2', '.', 'Ä **', 'Major', 'Ä Required', 'Ä Courses', '**:', 'Ä ', '15', 'Ä credits', '\\\\n', '3', '.', 'Ä **', 'Elect', 'ives', 'Ä (', 'Special', 'ization', ')**', ':', 'Ä ', '9', 'Ä credits', '\\\\n', '4', '.', 'Ä **', 'Total', 'Ä Major', 'Ä Credits', '**:', 'Ä ', '60', 'Ä credits', '\\\\n', 'This', 'Ä stringent', 'Ä requirement', 'Ä reflects', 'Ä the', 'Ä program', \"'s\", 'Ä commitment', 'Ä to', 'Ä providing', 'Ä a', 'Ä comprehensive', 'Ä education', 'Ä that', 'Ä prepares', 'Ä students', 'Ä for', 'Ä advanced', 'Ä research', 'Ä and', 'Ä industry', 'Ä applications', 'Ä within', 'Ä the', 'Ä field', 'Ä of', 'Ä mechanical', 'Ä engineering', '.', 'Ä The', 'Ä emphasis', 'Ä on', 'Ä both', 'Ä required', 'Ä and', 'Ä elective', 'Ä courses', 'Ä ensures', 'Ä that', 'Ä graduates', 'Ä not', 'Ä only', 'Ä possess', 'Ä core', 'Ä knowledge', 'Ä but', 'Ä also', 'Ä have', 'Ä the', 'Ä flexibility', 'Ä to', 'Ä tailor', 'Ä their', 'Ä education', 'Ä according', 'Ä to', 'Ä their', 'Ä interests', 'Ä and', 'Ä career', 'Ä goals', '.', '<|eot_id|>']\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
